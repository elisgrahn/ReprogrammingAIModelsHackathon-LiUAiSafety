import os
from typing import Literal

import goodfire

def setup_client(variant_size: Literal[8, 70]):
    """Setup the GoodFire client and variant.

    Args:
        variant_size: The size of the variant to use in billion parameters, either 8 or 70.

    Raises:
        ValueError: If the variant_size is not 8 or 70.

    Returns:
        tuple[goodfire.Client, goodfire.Variant]: The GoodFire client and variant.
    """
    if variant_size == 8:
        v_name = "meta-llama/Meta-Llama-3-8B-Instruct"
    elif variant_size == 70:
        v_name = "meta-llama/Meta-Llama-3.1-70B-Instruct"
    else:
        raise ValueError(f"Invalid variant_size: {variant_size}")

    api_key_path = os.path.join(os.path.dirname(__file__), 'goodfire.key')
    if not os.path.exists(api_key_path):
        raise FileNotFoundError(f"API key file not found. Create an API key at:\n\t{api_key_path}")
    api_key = open(api_key_path).read().strip()

    client = goodfire.Client(api_key)
    variant = goodfire.Variant(v_name)

    return client, variant


def response(
    client: goodfire.Client,
    variant: goodfire.Variant,
    input: str,
    max_tokens: int = 100
) -> str:
    """Generate a response from the given input.

    Args:
        client (goodfire.Client): GoodFire client.
        variant (goodfire.Variant): GoodFire variant.
        input (str): The input to generate a response for.
        max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 100.

    Returns:
        str: The response generated by the assistant.
    """
    return client.chat.completions.create(
        [{"role": "user", "content": input}],
        model=variant,
        stream=False,
        max_completion_tokens=max_tokens,
    ).choices[0].message["content"]


def generate_datasets(
    questions: list[str],
    answers_1: list[str],
    answers_2: list[str],
) -> tuple[list[list[dict]], list[list[dict]]]:
    """Generate two datasets from the given questions and answers.

    Args:
        questions (list[str]): The list of questions asked by the user.
        answers_1 (list[str]): The list of answers given by the assistant_1.
        answers_2 (list[str]): The list of answers given by the assistant_2.

    Returns:
        tuple[list[list[dict]], list[list[dict]]]: The two datasets generated from the given questions and answers.
    """
    dataset_1 = []
    dataset_2 = []

    for question, answer_1, answer_2 in zip(questions, answers_1, answers_2):
        dataset_1.append([
            {"role": "user", "content": question},
            {"role": "assistant", "content": answer_1},
        ])
        dataset_2.append([
            {"role": "user", "content": question},
            {"role": "assistant", "content": answer_2},
        ])
    return dataset_1, dataset_2


def feature_uuids(features: goodfire.FeatureGroup) -> list[str]:
    """Get the UUIDs of the features in the given feature group.

    Args:
        features (goodfire.FeatureGroup): The feature group.

    Returns:
        list[str]: The list of UUIDs of the features in the given feature group.
    """
    return [feature.uuid for feature in features.features]


def conversation(
    client: goodfire.Client,
    variant: goodfire.Variant,
    questions: list[str],
    max_tokens: int = 100,
):
    """Pretty print a conversation between the user and the assistant.

    Args:
        client (goodfire.Client): GoodFire client.
        variant (goodfire.Variant): GoodFire variant.
        questions (list[str]): The list of questions asked by the user.
        max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 100.
    """
    for question in questions:
        print("\n-----------------------------------\n")
        print(f"{question}\n{'-'*20}\n{response(client, variant, question, max_tokens)}")
